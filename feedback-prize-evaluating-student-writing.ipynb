{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40077ab3",
   "metadata": {
    "papermill": {
     "duration": 0.100456,
     "end_time": "2022-03-15T20:00:30.483279",
     "exception": false,
     "start_time": "2022-03-15T20:00:30.382823",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4124f60d",
   "metadata": {
    "papermill": {
     "duration": 0.074777,
     "end_time": "2022-03-15T20:00:30.654513",
     "exception": false,
     "start_time": "2022-03-15T20:00:30.579736",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Libraries Import\n",
    "\n",
    "## Regular Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aef9f58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:00:30.817285Z",
     "iopub.status.busy": "2022-03-15T20:00:30.810451Z",
     "iopub.status.idle": "2022-03-15T20:01:42.095063Z",
     "shell.execute_reply": "2022-03-15T20:01:42.094483Z",
     "shell.execute_reply.started": "2022-03-15T18:45:07.191953Z"
    },
    "papermill": {
     "duration": 71.371947,
     "end_time": "2022-03-15T20:01:42.095218",
     "exception": false,
     "start_time": "2022-03-15T20:00:30.723271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting GPUtil\r\n",
      "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hBuilding wheels for collected packages: GPUtil\r\n",
      "  Building wheel for GPUtil (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=2f03ac4f76a52ad2700d09fd413d8ae098223eb27295a58ef0451f49378b4aee\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\r\n",
      "Successfully built GPUtil\r\n",
      "Installing collected packages: GPUtil\r\n",
      "Successfully installed GPUtil-1.4.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (1.9.1)\r\n",
      "Collecting torch\r\n",
      "  Downloading torch-1.11.0-cp37-cp37m-manylinux1_x86_64.whl (750.6 MB)\r\n",
      "     |████████████████████████████████| 750.6 MB 8.9 kB/s             \r\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (4.0.1)\r\n",
      "Installing collected packages: torch\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 1.9.1\r\n",
      "    Uninstalling torch-1.9.1:\r\n",
      "      Successfully uninstalled torch-1.9.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "fastai 2.5.3 requires torch<1.11,>=1.7.0, but you have torch 1.11.0 which is incompatible.\r\n",
      "allennlp 2.9.0 requires torch<1.11.0,>=1.6.0, but you have torch 1.11.0 which is incompatible.\u001b[0m\r\n",
      "Successfully installed torch-1.11.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install GPUtil\n",
    "!pip install torch --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fba46257",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:01:42.633974Z",
     "iopub.status.busy": "2022-03-15T20:01:42.633071Z",
     "iopub.status.idle": "2022-03-15T20:01:42.634557Z",
     "shell.execute_reply": "2022-03-15T20:01:42.634955Z",
     "shell.execute_reply.started": "2022-03-15T18:45:22.535847Z"
    },
    "papermill": {
     "duration": 0.275448,
     "end_time": "2022-03-15T20:01:42.635103",
     "exception": false,
     "start_time": "2022-03-15T20:01:42.359655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9eaf05",
   "metadata": {
    "papermill": {
     "duration": 0.280672,
     "end_time": "2022-03-15T20:01:43.181114",
     "exception": false,
     "start_time": "2022-03-15T20:01:42.900442",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Auxiliary Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c173f3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:01:43.720366Z",
     "iopub.status.busy": "2022-03-15T20:01:43.719727Z",
     "iopub.status.idle": "2022-03-15T20:01:43.721267Z",
     "shell.execute_reply": "2022-03-15T20:01:43.720824Z",
     "shell.execute_reply.started": "2022-03-15T18:45:22.543611Z"
    },
    "papermill": {
     "duration": 0.273383,
     "end_time": "2022-03-15T20:01:43.721379",
     "exception": false,
     "start_time": "2022-03-15T20:01:43.447996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e46213",
   "metadata": {
    "papermill": {
     "duration": 0.298812,
     "end_time": "2022-03-15T20:01:44.295816",
     "exception": false,
     "start_time": "2022-03-15T20:01:43.997004",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Visualization Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b451f24e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:01:44.836982Z",
     "iopub.status.busy": "2022-03-15T20:01:44.836162Z",
     "iopub.status.idle": "2022-03-15T20:01:44.837556Z",
     "shell.execute_reply": "2022-03-15T20:01:44.837953Z",
     "shell.execute_reply.started": "2022-03-15T18:45:22.551962Z"
    },
    "papermill": {
     "duration": 0.273292,
     "end_time": "2022-03-15T20:01:44.838101",
     "exception": false,
     "start_time": "2022-03-15T20:01:44.564809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5823423",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:01:45.374433Z",
     "iopub.status.busy": "2022-03-15T20:01:45.373575Z",
     "iopub.status.idle": "2022-03-15T20:01:47.332459Z",
     "shell.execute_reply": "2022-03-15T20:01:47.332971Z",
     "shell.execute_reply.started": "2022-03-15T18:45:22.563954Z"
    },
    "papermill": {
     "duration": 2.232978,
     "end_time": "2022-03-15T20:01:47.333139",
     "exception": false,
     "start_time": "2022-03-15T20:01:45.100161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizerFast, RobertaForTokenClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pdb\n",
    "import torch\n",
    "from torch import cuda\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "MODEL_NAME = \"../input/roberta-base\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17de0e8",
   "metadata": {
    "papermill": {
     "duration": 0.470693,
     "end_time": "2022-03-15T20:01:48.290785",
     "exception": false,
     "start_time": "2022-03-15T20:01:47.820092",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c403cc6",
   "metadata": {
    "papermill": {
     "duration": 0.324945,
     "end_time": "2022-03-15T20:01:49.070941",
     "exception": false,
     "start_time": "2022-03-15T20:01:48.745996",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Extraction\n",
    "\n",
    "## Main Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78bb5be6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:01:49.905641Z",
     "iopub.status.busy": "2022-03-15T20:01:49.905100Z",
     "iopub.status.idle": "2022-03-15T20:01:51.388549Z",
     "shell.execute_reply": "2022-03-15T20:01:51.388008Z",
     "shell.execute_reply.started": "2022-03-15T18:45:22.572625Z"
    },
    "papermill": {
     "duration": 1.810298,
     "end_time": "2022-03-15T20:01:51.388669",
     "exception": false,
     "start_time": "2022-03-15T20:01:49.578371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/feedback-prize-2021/train.csv')\n",
    "sample_submission = pd.read_csv('../input/feedback-prize-2021/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deb3dbb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:01:51.985120Z",
     "iopub.status.busy": "2022-03-15T20:01:51.984238Z",
     "iopub.status.idle": "2022-03-15T20:01:52.005824Z",
     "shell.execute_reply": "2022-03-15T20:01:52.006261Z",
     "shell.execute_reply.started": "2022-03-15T18:45:24.052167Z"
    },
    "papermill": {
     "duration": 0.320796,
     "end_time": "2022-03-15T20:01:52.006403",
     "exception": false,
     "start_time": "2022-03-15T20:01:51.685607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144293, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>230.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>313.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>402.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>759.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  discourse_id  discourse_start  discourse_end  \\\n",
       "0  423A1CA112E2  1.622628e+12              8.0          229.0   \n",
       "1  423A1CA112E2  1.622628e+12            230.0          312.0   \n",
       "2  423A1CA112E2  1.622628e+12            313.0          401.0   \n",
       "3  423A1CA112E2  1.622628e+12            402.0          758.0   \n",
       "4  423A1CA112E2  1.622628e+12            759.0          886.0   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Modern humans today are always on their phone....           Lead   \n",
       "1  They are some really bad consequences when stu...       Position   \n",
       "2  Some certain areas in the United States ban ph...       Evidence   \n",
       "3  When people have phones, they know about certa...       Evidence   \n",
       "4  Driving is one of the way how to get around. P...          Claim   \n",
       "\n",
       "  discourse_type_num                                   predictionstring  \n",
       "0             Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  \n",
       "1         Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  \n",
       "2         Evidence 1    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  \n",
       "3         Evidence 2  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...  \n",
       "4            Claim 1  139 140 141 142 143 144 145 146 147 148 149 15...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dbe637",
   "metadata": {
    "papermill": {
     "duration": 0.28563,
     "end_time": "2022-03-15T20:01:52.579361",
     "exception": false,
     "start_time": "2022-03-15T20:01:52.293731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd792cb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:01:53.147022Z",
     "iopub.status.busy": "2022-03-15T20:01:53.146296Z",
     "iopub.status.idle": "2022-03-15T20:01:53.149783Z",
     "shell.execute_reply": "2022-03-15T20:01:53.150216Z",
     "shell.execute_reply.started": "2022-03-15T18:45:24.079784Z"
    },
    "papermill": {
     "duration": 0.286,
     "end_time": "2022-03-15T20:01:53.150356",
     "exception": false,
     "start_time": "2022-03-15T20:01:52.864356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data consists of 144293 annotaions\n"
     ]
    }
   ],
   "source": [
    "print(f'Training data consists of {train.shape[0]} annotaions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68ff0089",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:01:53.717476Z",
     "iopub.status.busy": "2022-03-15T20:01:53.707751Z",
     "iopub.status.idle": "2022-03-15T20:01:53.808650Z",
     "shell.execute_reply": "2022-03-15T20:01:53.809145Z",
     "shell.execute_reply.started": "2022-03-15T18:45:24.087243Z"
    },
    "papermill": {
     "duration": 0.395461,
     "end_time": "2022-03-15T20:01:53.809298",
     "exception": false,
     "start_time": "2022-03-15T20:01:53.413837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50355\n",
      "------------------------------------\n",
      "44\n",
      "['Lead 1' 'Position 1' 'Evidence 1' 'Evidence 2' 'Claim 1' 'Evidence 3'\n",
      " 'Evidence 4' 'Claim 2' 'Evidence 5' 'Concluding Statement 1'\n",
      " 'Counterclaim 1' 'Rebuttal 1' 'Claim 3' 'Claim 4' 'Claim 5' 'Claim 6'\n",
      " 'Claim 7' 'Counterclaim 2' 'Rebuttal 2' 'Counterclaim 3' 'Rebuttal 3'\n",
      " 'Evidence 6' 'Lead 2' 'Counterclaim 4' 'Counterclaim 5' 'Counterclaim 6'\n",
      " 'Evidence 7' 'Claim 8' 'Evidence 8' 'Concluding Statement 2' 'Rebuttal 4'\n",
      " 'Rebuttal 5' 'Claim 9' 'Position 2' 'Claim 10' 'Claim 11' 'Claim 12'\n",
      " 'Evidence 9' 'Concluding Statement 3' 'Concluding Statement 4'\n",
      " 'Evidence 10' 'Evidence 11' 'Rebuttal 6' 'Evidence 12']\n",
      "------------------------------------\n",
      "['Lead' 'Position' 'Evidence' 'Claim' 'Concluding Statement'\n",
      " 'Counterclaim' 'Rebuttal']\n"
     ]
    }
   ],
   "source": [
    "print(train[\"predictionstring\"].nunique())\n",
    "print(\"------------------------------------\")\n",
    "print(train[\"discourse_type_num\"].nunique())\n",
    "print(train[\"discourse_type_num\"].unique())\n",
    "print(\"------------------------------------\")\n",
    "print(train[\"discourse_type\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "105871fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:01:54.354467Z",
     "iopub.status.busy": "2022-03-15T20:01:54.351400Z",
     "iopub.status.idle": "2022-03-15T20:01:54.794905Z",
     "shell.execute_reply": "2022-03-15T20:01:54.794058Z",
     "shell.execute_reply.started": "2022-03-15T18:45:24.199233Z"
    },
    "papermill": {
     "duration": 0.716842,
     "end_time": "2022-03-15T20:01:54.795078",
     "exception": false,
     "start_time": "2022-03-15T20:01:54.078236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train[\"discourse_len\"] = train[\"discourse_text\"].apply(lambda x:len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fc5fc5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:01:55.360896Z",
     "iopub.status.busy": "2022-03-15T20:01:55.360002Z",
     "iopub.status.idle": "2022-03-15T20:01:55.683151Z",
     "shell.execute_reply": "2022-03-15T20:01:55.682376Z",
     "shell.execute_reply.started": "2022-03-15T18:45:24.634305Z"
    },
    "papermill": {
     "duration": 0.616176,
     "end_time": "2022-03-15T20:01:55.683288",
     "exception": false,
     "start_time": "2022-03-15T20:01:55.067112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train[\"predictionstring_len\"] = train[\"predictionstring\"].apply(lambda x:len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8b552d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:01:56.219694Z",
     "iopub.status.busy": "2022-03-15T20:01:56.218088Z",
     "iopub.status.idle": "2022-03-15T20:01:56.220310Z",
     "shell.execute_reply": "2022-03-15T20:01:56.220726Z",
     "shell.execute_reply.started": "2022-03-15T18:45:24.962487Z"
    },
    "papermill": {
     "duration": 0.274876,
     "end_time": "2022-03-15T20:01:56.220882",
     "exception": false,
     "start_time": "2022-03-15T20:01:55.946006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train[\"len_predict\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "597d8ce3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:01:56.758686Z",
     "iopub.status.busy": "2022-03-15T20:01:56.758099Z",
     "iopub.status.idle": "2022-03-15T20:02:32.607638Z",
     "shell.execute_reply": "2022-03-15T20:02:32.607166Z",
     "shell.execute_reply.started": "2022-03-15T18:45:24.970842Z"
    },
    "papermill": {
     "duration": 36.12303,
     "end_time": "2022-03-15T20:02:32.607766",
     "exception": false,
     "start_time": "2022-03-15T20:01:56.484736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(train[\"discourse_len\"])):\n",
    "    if train[\"discourse_len\"][i] == train[\"predictionstring_len\"][i]:\n",
    "        train[\"len_predict\"][i] = 0\n",
    "    else:\n",
    "        train[\"len_predict\"][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92f8b9b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:02:33.268504Z",
     "iopub.status.busy": "2022-03-15T20:02:33.267691Z",
     "iopub.status.idle": "2022-03-15T20:02:33.274375Z",
     "shell.execute_reply": "2022-03-15T20:02:33.273672Z",
     "shell.execute_reply.started": "2022-03-15T18:46:00.684093Z"
    },
    "papermill": {
     "duration": 0.398269,
     "end_time": "2022-03-15T20:02:33.274543",
     "exception": false,
     "start_time": "2022-03-15T20:02:32.876274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"len_predict\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bfc0d1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:02:33.994564Z",
     "iopub.status.busy": "2022-03-15T20:02:33.993576Z",
     "iopub.status.idle": "2022-03-15T20:02:34.006234Z",
     "shell.execute_reply": "2022-03-15T20:02:34.006721Z",
     "shell.execute_reply.started": "2022-03-15T18:46:00.694878Z"
    },
    "papermill": {
     "duration": 0.300541,
     "end_time": "2022-03-15T20:02:34.006871",
     "exception": false,
     "start_time": "2022-03-15T20:02:33.706330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>discourse_len</th>\n",
       "      <th>predictionstring_len</th>\n",
       "      <th>len_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>230.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>313.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>402.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>759.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  discourse_id  discourse_start  discourse_end  \\\n",
       "0  423A1CA112E2  1.622628e+12              8.0          229.0   \n",
       "1  423A1CA112E2  1.622628e+12            230.0          312.0   \n",
       "2  423A1CA112E2  1.622628e+12            313.0          401.0   \n",
       "3  423A1CA112E2  1.622628e+12            402.0          758.0   \n",
       "4  423A1CA112E2  1.622628e+12            759.0          886.0   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Modern humans today are always on their phone....           Lead   \n",
       "1  They are some really bad consequences when stu...       Position   \n",
       "2  Some certain areas in the United States ban ph...       Evidence   \n",
       "3  When people have phones, they know about certa...       Evidence   \n",
       "4  Driving is one of the way how to get around. P...          Claim   \n",
       "\n",
       "  discourse_type_num                                   predictionstring  \\\n",
       "0             Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...   \n",
       "1         Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59   \n",
       "2         Evidence 1    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75   \n",
       "3         Evidence 2  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...   \n",
       "4            Claim 1  139 140 141 142 143 144 145 146 147 148 149 15...   \n",
       "\n",
       "   discourse_len  predictionstring_len  len_predict  \n",
       "0             44                    44            0  \n",
       "1             15                    15            0  \n",
       "2             16                    16            0  \n",
       "3             63                    63            0  \n",
       "4             24                    24            0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63719377",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:02:34.579179Z",
     "iopub.status.busy": "2022-03-15T20:02:34.578377Z",
     "iopub.status.idle": "2022-03-15T20:02:34.580103Z",
     "shell.execute_reply": "2022-03-15T20:02:34.579665Z",
     "shell.execute_reply.started": "2022-03-15T18:46:00.715124Z"
    },
    "papermill": {
     "duration": 0.28013,
     "end_time": "2022-03-15T20:02:34.580216",
     "exception": false,
     "start_time": "2022-03-15T20:02:34.300086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test_names, test_texts = [], []\n",
    "#for f in tqdm(list(os.listdir('../input/feedback-prize-2021/test'))):\n",
    "#    test_names.append(f.replace('.txt', ''))\n",
    "#    test_texts.append(open('../input/feedback-prize-2021/test/' + f, 'r').read())\n",
    "#test_texts = pd.DataFrame({'id': test_names, 'text': test_texts})\n",
    "#\n",
    "#test_texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3c30aef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:02:35.140702Z",
     "iopub.status.busy": "2022-03-15T20:02:35.140172Z",
     "iopub.status.idle": "2022-03-15T20:03:24.281827Z",
     "shell.execute_reply": "2022-03-15T20:03:24.282296Z",
     "shell.execute_reply.started": "2022-03-15T18:46:00.723449Z"
    },
    "papermill": {
     "duration": 49.425988,
     "end_time": "2022-03-15T20:03:24.282457",
     "exception": false,
     "start_time": "2022-03-15T20:02:34.856469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15594/15594 [00:48<00:00, 319.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62C57C524CD2</td>\n",
       "      <td>I think we should be able to play in a sport i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80667AD3FFD8</td>\n",
       "      <td>Some schools require summer projects for stude...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21868C40B94F</td>\n",
       "      <td>Driverless cars have been argued and talked ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87A6EF3113C6</td>\n",
       "      <td>The author of \"The Challenge of Exploring Venu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24687D08CFDA</td>\n",
       "      <td>Wow, from the mar really look like humans face...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text\n",
       "0  62C57C524CD2  I think we should be able to play in a sport i...\n",
       "1  80667AD3FFD8  Some schools require summer projects for stude...\n",
       "2  21868C40B94F  Driverless cars have been argued and talked ab...\n",
       "3  87A6EF3113C6  The author of \"The Challenge of Exploring Venu...\n",
       "4  24687D08CFDA  Wow, from the mar really look like humans face..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_names, train_texts = [], []\n",
    "for f in tqdm(list(os.listdir('../input/feedback-prize-2021/train'))):\n",
    "    test_names.append(f.replace('.txt', ''))\n",
    "    train_texts.append(open('../input/feedback-prize-2021/train/' + f, 'r').read())\n",
    "train_text_df = pd.DataFrame({'id': test_names, 'text': train_texts})\n",
    "\n",
    "train_text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e90ce0df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:03:25.127612Z",
     "iopub.status.busy": "2022-03-15T20:03:25.126594Z",
     "iopub.status.idle": "2022-03-15T20:09:05.038115Z",
     "shell.execute_reply": "2022-03-15T20:09:05.038706Z",
     "shell.execute_reply.started": "2022-03-15T18:46:51.564546Z"
    },
    "papermill": {
     "duration": 340.335142,
     "end_time": "2022-03-15T20:09:05.038918",
     "exception": false,
     "start_time": "2022-03-15T20:03:24.703776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15594it [05:39, 45.88it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df = train.copy()\n",
    "all_entities = []\n",
    "for i in tqdm(train_text_df.iterrows()):\n",
    "    total = i[1]['text'].split(' ').__len__()\n",
    "    start = -1\n",
    "    entities = []\n",
    "    for j in train_df[train_df['id'] == i[1]['id']].iterrows():\n",
    "        discourse = j[1]['discourse_type']\n",
    "        list_ix = j[1]['predictionstring'].split(' ')\n",
    "        ent = [f\"I-{discourse}\" for ix in list_ix]\n",
    "        ent[0] = f\"B-{discourse}\"\n",
    "        ds = int(list_ix[0])\n",
    "        de = int(list_ix[-1])\n",
    "        if start < ds-1:\n",
    "            ent_add = ['O' for ix in range(int(ds-1-start))]\n",
    "            ent = ent_add + ent\n",
    "        entities.extend(ent)\n",
    "        start = de\n",
    "    if len(entities) < total:\n",
    "        ent_add = [\"O\" for ix in range(total-len(entities))]\n",
    "        entities += ent_add\n",
    "    else:\n",
    "        entities = entities[:total]\n",
    "    all_entities.append(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46cb8118",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:09:07.830050Z",
     "iopub.status.busy": "2022-03-15T20:09:07.829331Z",
     "iopub.status.idle": "2022-03-15T20:09:07.832294Z",
     "shell.execute_reply": "2022-03-15T20:09:07.832792Z",
     "shell.execute_reply.started": "2022-03-15T18:52:30.503243Z"
    },
    "papermill": {
     "duration": 1.408724,
     "end_time": "2022-03-15T20:09:07.832953",
     "exception": false,
     "start_time": "2022-03-15T20:09:06.424229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62C57C524CD2</td>\n",
       "      <td>I think we should be able to play in a sport i...</td>\n",
       "      <td>[B-Position, I-Position, I-Position, I-Positio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80667AD3FFD8</td>\n",
       "      <td>Some schools require summer projects for stude...</td>\n",
       "      <td>[B-Position, I-Position, I-Position, I-Positio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21868C40B94F</td>\n",
       "      <td>Driverless cars have been argued and talked ab...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87A6EF3113C6</td>\n",
       "      <td>The author of \"The Challenge of Exploring Venu...</td>\n",
       "      <td>[B-Position, I-Position, I-Position, I-Positio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24687D08CFDA</td>\n",
       "      <td>Wow, from the mar really look like humans face...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text  \\\n",
       "0  62C57C524CD2  I think we should be able to play in a sport i...   \n",
       "1  80667AD3FFD8  Some schools require summer projects for stude...   \n",
       "2  21868C40B94F  Driverless cars have been argued and talked ab...   \n",
       "3  87A6EF3113C6  The author of \"The Challenge of Exploring Venu...   \n",
       "4  24687D08CFDA  Wow, from the mar really look like humans face...   \n",
       "\n",
       "                                            entities  \n",
       "0  [B-Position, I-Position, I-Position, I-Positio...  \n",
       "1  [B-Position, I-Position, I-Position, I-Positio...  \n",
       "2  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  \n",
       "3  [B-Position, I-Position, I-Position, I-Positio...  \n",
       "4  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_df['entities'] = all_entities\n",
    "train_text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b7d7b55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:09:10.931440Z",
     "iopub.status.busy": "2022-03-15T20:09:10.930629Z",
     "iopub.status.idle": "2022-03-15T20:09:10.933441Z",
     "shell.execute_reply": "2022-03-15T20:09:10.932988Z",
     "shell.execute_reply.started": "2022-03-15T18:52:30.528682Z"
    },
    "papermill": {
     "duration": 1.564755,
     "end_time": "2022-03-15T20:09:10.933560",
     "exception": false,
     "start_time": "2022-03-15T20:09:09.368805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {'model_name': '/kaggle/input/roberta-base/',\n",
    "         'max_length': 512,\n",
    "         'train_batch_size':8,\n",
    "         'valid_batch_size':16,\n",
    "         'epochs':3,\n",
    "         'learning_rate':1e-05,\n",
    "         'max_grad_norm':10,\n",
    "         'device': 'cuda' if cuda.is_available() else 'cpu'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1365ff98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:09:14.227545Z",
     "iopub.status.busy": "2022-03-15T20:09:14.226723Z",
     "iopub.status.idle": "2022-03-15T20:09:14.230305Z",
     "shell.execute_reply": "2022-03-15T20:09:14.229838Z",
     "shell.execute_reply.started": "2022-03-15T18:52:30.581747Z"
    },
    "papermill": {
     "duration": 1.590872,
     "end_time": "2022-03-15T20:09:14.230432",
     "exception": false,
     "start_time": "2022-03-15T20:09:12.639560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_labels = ['O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim', 'B-Counterclaim', 'I-Counterclaim', \n",
    "          'B-Rebuttal', 'I-Rebuttal', 'B-Evidence', 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement']\n",
    "\n",
    "labels_to_ids = {v:k for k,v in enumerate(output_labels)}\n",
    "ids_to_labels = {k:v for k,v in enumerate(output_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d1e2d4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:09:16.990541Z",
     "iopub.status.busy": "2022-03-15T20:09:16.987928Z",
     "iopub.status.idle": "2022-03-15T20:09:16.992953Z",
     "shell.execute_reply": "2022-03-15T20:09:16.993422Z",
     "shell.execute_reply.started": "2022-03-15T18:52:30.591047Z"
    },
    "papermill": {
     "duration": 1.384872,
     "end_time": "2022-03-15T20:09:16.993566",
     "exception": false,
     "start_time": "2022-03-15T20:09:15.608694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'B-Lead': 1, 'I-Lead': 2, 'B-Position': 3, 'I-Position': 4, 'B-Claim': 5, 'I-Claim': 6, 'B-Counterclaim': 7, 'I-Counterclaim': 8, 'B-Rebuttal': 9, 'I-Rebuttal': 10, 'B-Evidence': 11, 'I-Evidence': 12, 'B-Concluding Statement': 13, 'I-Concluding Statement': 14}\n",
      "{0: 'O', 1: 'B-Lead', 2: 'I-Lead', 3: 'B-Position', 4: 'I-Position', 5: 'B-Claim', 6: 'I-Claim', 7: 'B-Counterclaim', 8: 'I-Counterclaim', 9: 'B-Rebuttal', 10: 'I-Rebuttal', 11: 'B-Evidence', 12: 'I-Evidence', 13: 'B-Concluding Statement', 14: 'I-Concluding Statement'}\n"
     ]
    }
   ],
   "source": [
    "print(labels_to_ids)\n",
    "print(ids_to_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4edae565",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:09:19.761567Z",
     "iopub.status.busy": "2022-03-15T20:09:19.760774Z",
     "iopub.status.idle": "2022-03-15T20:09:25.775217Z",
     "shell.execute_reply": "2022-03-15T20:09:25.774703Z",
     "shell.execute_reply.started": "2022-03-15T18:52:30.602271Z"
    },
    "papermill": {
     "duration": 7.419827,
     "end_time": "2022-03-15T20:09:25.775363",
     "exception": false,
     "start_time": "2022-03-15T20:09:18.355536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /kaggle/input/roberta-base/ were not used when initializing RobertaForTokenClassification: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at /kaggle/input/roberta-base/ and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "\n",
    "model = RobertaForTokenClassification.from_pretrained(config['model_name'], num_labels=len(output_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e158cf17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:09:28.556697Z",
     "iopub.status.busy": "2022-03-15T20:09:28.555987Z",
     "iopub.status.idle": "2022-03-15T20:09:28.559207Z",
     "shell.execute_reply": "2022-03-15T20:09:28.558707Z",
     "shell.execute_reply.started": "2022-03-15T18:52:37.417845Z"
    },
    "papermill": {
     "duration": 1.398204,
     "end_time": "2022-03-15T20:09:28.559328",
     "exception": false,
     "start_time": "2022-03-15T20:09:27.161124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # step 1: get the sentence and word labels \n",
    "        sentence = self.data.text[index]\n",
    "        word_labels = self.data.entities[index]\n",
    "\n",
    "        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n",
    "        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n",
    "        encoding = self.tokenizer(sentence,\n",
    "#                              is_pretokenized=True, \n",
    "#                                   is_split_into_words=True,\n",
    "                             return_offsets_mapping=True, \n",
    "                             padding='max_length', \n",
    "                             truncation=True,\n",
    "                            max_length=self.max_len)\n",
    "        \n",
    "        # step 3: create token labels only for first word pieces of each tokenized word\n",
    "#         pdb.set_trace()\n",
    "        labels = [labels_to_ids[label] for label in word_labels] \n",
    "        # code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\n",
    "        # create an empty array of -100 of length max_length\n",
    "        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n",
    "#         print(len(sentence), len(labels))\n",
    "        # set only labels whose first offset position is 0 and the second is not 0\n",
    "        i = 0\n",
    "        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
    "#             print(idx)\n",
    "            if mapping[0] != 0 and mapping[0] != encoding['offset_mapping'][idx-1][1]:\n",
    "            # overwrite label\n",
    "#             pdb.set_trace()\n",
    "#             print(mapping)\n",
    "#             print(encoded_labels.shape, len(labels), idx, i)\n",
    "                try:\n",
    "                    encoded_labels[idx] = labels[i]\n",
    "                except:\n",
    "                    pass\n",
    "                i += 1\n",
    "            else:\n",
    "                if idx==1:\n",
    "    #                 print(idx)\n",
    "                    encoded_labels[idx] = labels[i]\n",
    "                    i += 1\n",
    "        # step 4: turn everything into PyTorch tensors\n",
    "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.as_tensor(encoded_labels)\n",
    "        \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23664ffb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:09:31.693585Z",
     "iopub.status.busy": "2022-03-15T20:09:31.692601Z",
     "iopub.status.idle": "2022-03-15T20:09:31.718499Z",
     "shell.execute_reply": "2022-03-15T20:09:31.717819Z",
     "shell.execute_reply.started": "2022-03-15T18:52:37.430886Z"
    },
    "papermill": {
     "duration": 1.700311,
     "end_time": "2022-03-15T20:09:31.718660",
     "exception": false,
     "start_time": "2022-03-15T20:09:30.018349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (15594, 2)\n",
      "TRAIN Dataset: (12475, 2)\n",
      "TEST Dataset: (3119, 2)\n"
     ]
    }
   ],
   "source": [
    "data = train_text_df[['text', 'entities']]\n",
    "train_size = 0.8\n",
    "train_dataset = data.sample(frac=train_size,random_state=200)\n",
    "test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(data.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = dataset(train_dataset, tokenizer, config['max_length'])\n",
    "testing_set = dataset(test_dataset, tokenizer, config['max_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "107a819d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:09:34.561895Z",
     "iopub.status.busy": "2022-03-15T20:09:34.561285Z",
     "iopub.status.idle": "2022-03-15T20:09:34.563710Z",
     "shell.execute_reply": "2022-03-15T20:09:34.564111Z",
     "shell.execute_reply.started": "2022-03-15T18:52:37.462603Z"
    },
    "papermill": {
     "duration": 1.391569,
     "end_time": "2022-03-15T20:09:34.564255",
     "exception": false,
     "start_time": "2022-03-15T20:09:33.172686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_params = {'batch_size': config['train_batch_size'],\n",
    "                'shuffle': True,\n",
    "                'num_workers': 1,\n",
    "                'pin_memory':True\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': config['valid_batch_size'],\n",
    "                'shuffle': True,\n",
    "                'num_workers': 1,\n",
    "                'pin_memory':True\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "625970cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:09:37.367623Z",
     "iopub.status.busy": "2022-03-15T20:09:37.366771Z",
     "iopub.status.idle": "2022-03-15T20:09:37.369607Z",
     "shell.execute_reply": "2022-03-15T20:09:37.370106Z",
     "shell.execute_reply.started": "2022-03-15T18:52:37.470487Z"
    },
    "papermill": {
     "duration": 1.392331,
     "end_time": "2022-03-15T20:09:37.370257",
     "exception": false,
     "start_time": "2022-03-15T20:09:35.977926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = config['device']\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "daf9ea4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:09:40.432378Z",
     "iopub.status.busy": "2022-03-15T20:09:40.431633Z",
     "iopub.status.idle": "2022-03-15T20:09:40.435377Z",
     "shell.execute_reply": "2022-03-15T20:09:40.434617Z",
     "shell.execute_reply.started": "2022-03-15T18:52:37.481531Z"
    },
    "papermill": {
     "duration": 1.654951,
     "end_time": "2022-03-15T20:09:40.435513",
     "exception": false,
     "start_time": "2022-03-15T20:09:38.780562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7becd69f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:09:43.521020Z",
     "iopub.status.busy": "2022-03-15T20:09:43.520183Z",
     "iopub.status.idle": "2022-03-15T20:09:44.309686Z",
     "shell.execute_reply": "2022-03-15T20:09:44.310410Z",
     "shell.execute_reply.started": "2022-03-15T18:52:37.900212Z"
    },
    "papermill": {
     "duration": 2.436132,
     "end_time": "2022-03-15T20:09:44.310607",
     "exception": false,
     "start_time": "2022-03-15T20:09:41.874475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 10% |  2% |\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "\n",
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()                             \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "free_gpu_cache()                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d0dce9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:09:47.584983Z",
     "iopub.status.busy": "2022-03-15T20:09:47.584014Z",
     "iopub.status.idle": "2022-03-15T20:09:49.996600Z",
     "shell.execute_reply": "2022-03-15T20:09:49.997006Z",
     "shell.execute_reply.started": "2022-03-15T18:52:38.773236Z"
    },
    "papermill": {
     "duration": 3.829297,
     "end_time": "2022-03-15T20:09:49.997163",
     "exception": false,
     "start_time": "2022-03-15T20:09:46.167866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.7935, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "inputs = training_set[2]\n",
    "input_ids = inputs[\"input_ids\"].unsqueeze(0)\n",
    "attention_mask = inputs[\"attention_mask\"].unsqueeze(0)\n",
    "labels = inputs[\"labels\"].unsqueeze(0)\n",
    "\n",
    "input_ids = input_ids.to(device)\n",
    "attention_mask = attention_mask.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "outputs = model(input_ids, attention_mask=attention_mask, labels=labels,\n",
    "               return_dict=False)\n",
    "initial_loss = outputs[0]\n",
    "initial_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "662103bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:09:52.790318Z",
     "iopub.status.busy": "2022-03-15T20:09:52.789642Z",
     "iopub.status.idle": "2022-03-15T20:09:52.793214Z",
     "shell.execute_reply": "2022-03-15T20:09:52.792704Z",
     "shell.execute_reply.started": "2022-03-15T18:56:54.633287Z"
    },
    "papermill": {
     "duration": 1.404007,
     "end_time": "2022-03-15T20:09:52.793335",
     "exception": false,
     "start_time": "2022-03-15T20:09:51.389328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=config['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "337779c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:09:55.818679Z",
     "iopub.status.busy": "2022-03-15T20:09:55.817768Z",
     "iopub.status.idle": "2022-03-15T20:09:55.819971Z",
     "shell.execute_reply": "2022-03-15T20:09:55.819560Z",
     "shell.execute_reply.started": "2022-03-15T18:57:57.548866Z"
    },
    "papermill": {
     "duration": 1.388752,
     "end_time": "2022-03-15T20:09:55.820091",
     "exception": false,
     "start_time": "2022-03-15T20:09:54.431339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    for idx, batch in enumerate(training_loader):\n",
    "        \n",
    "        ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "        labels = batch['labels'].to(device, dtype = torch.long)\n",
    "\n",
    "        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels,\n",
    "                               return_dict=False)\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += labels.size(0)\n",
    "        \n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "           \n",
    "        # compute training accuracy\n",
    "        flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        \n",
    "        # only compute accuracy at active labels\n",
    "        active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "        #active_labels = torch.where(active_accuracy, labels.view(-1), torch.tensor(-100).type_as(labels))\n",
    "        \n",
    "        labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "        \n",
    "        tr_labels.extend(labels)\n",
    "        tr_preds.extend(predictions)\n",
    "        \n",
    "        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "    \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=config['max_grad_norm']\n",
    "        )\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b13a9cbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:09:58.666815Z",
     "iopub.status.busy": "2022-03-15T20:09:58.666240Z",
     "iopub.status.idle": "2022-03-15T20:46:17.337804Z",
     "shell.execute_reply": "2022-03-15T20:46:17.338575Z",
     "shell.execute_reply.started": "2022-03-15T19:05:00.147125Z"
    },
    "papermill": {
     "duration": 2180.065725,
     "end_time": "2022-03-15T20:46:17.338795",
     "exception": false,
     "start_time": "2022-03-15T20:09:57.273070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training loss per 100 training steps: 2.7983627319335938\n",
      "Training loss per 100 training steps: 1.543988063783929\n",
      "Training loss per 100 training steps: 1.2964513983892565\n",
      "Training loss per 100 training steps: 1.1807487311949365\n",
      "Training loss per 100 training steps: 1.1130111681255617\n",
      "Training loss per 100 training steps: 1.065186740157609\n",
      "Training loss per 100 training steps: 1.027062260767386\n",
      "Training loss per 100 training steps: 0.9943992657515189\n",
      "Training loss per 100 training steps: 0.9713475199302335\n",
      "Training loss per 100 training steps: 0.9510026949888858\n",
      "Training loss per 100 training steps: 0.932294478634378\n",
      "Training loss per 100 training steps: 0.9165854840306776\n",
      "Training loss per 100 training steps: 0.901601126797491\n",
      "Training loss per 100 training steps: 0.8880725344220645\n",
      "Training loss per 100 training steps: 0.8763539803657763\n",
      "Training loss per 100 training steps: 0.8667862035885086\n",
      "Training loss epoch: 0.8617747047772775\n",
      "Training accuracy epoch: 0.730353100666691\n",
      "Training epoch: 2\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training loss per 100 training steps: 0.6364644765853882\n",
      "Training loss per 100 training steps: 0.6988884104360448\n",
      "Training loss per 100 training steps: 0.6845285677494695\n",
      "Training loss per 100 training steps: 0.675099266822948\n",
      "Training loss per 100 training steps: 0.6736648446901183\n",
      "Training loss per 100 training steps: 0.6745557126527775\n",
      "Training loss per 100 training steps: 0.6718885883217842\n",
      "Training loss per 100 training steps: 0.6735951712995385\n",
      "Training loss per 100 training steps: 0.670840055643396\n",
      "Training loss per 100 training steps: 0.6730515654886206\n",
      "Training loss per 100 training steps: 0.6736100477117163\n",
      "Training loss per 100 training steps: 0.6730754664277727\n",
      "Training loss per 100 training steps: 0.6731588232279022\n",
      "Training loss per 100 training steps: 0.6724789417953696\n",
      "Training loss per 100 training steps: 0.6724502535099476\n",
      "Training loss per 100 training steps: 0.6711458136525494\n",
      "Training loss epoch: 0.6708793758581846\n",
      "Training accuracy epoch: 0.7788962320326988\n",
      "Training epoch: 3\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training loss per 100 training steps: 0.5005819201469421\n",
      "Training loss per 100 training steps: 0.6082982001918378\n",
      "Training loss per 100 training steps: 0.6114817206835865\n",
      "Training loss per 100 training steps: 0.6074536574441333\n",
      "Training loss per 100 training steps: 0.6083245818454428\n",
      "Training loss per 100 training steps: 0.6127301477148623\n",
      "Training loss per 100 training steps: 0.6133529581563445\n",
      "Training loss per 100 training steps: 0.6137468827178917\n",
      "Training loss per 100 training steps: 0.6094056161378654\n",
      "Training loss per 100 training steps: 0.609881703186776\n",
      "Training loss per 100 training steps: 0.6085305491408387\n",
      "Training loss per 100 training steps: 0.6081027944287206\n",
      "Training loss per 100 training steps: 0.6057026608351566\n",
      "Training loss per 100 training steps: 0.6067645755939352\n",
      "Training loss per 100 training steps: 0.6065606088999081\n",
      "Training loss per 100 training steps: 0.6058364501800003\n",
      "Training loss epoch: 0.6052910942488756\n",
      "Training accuracy epoch: 0.7962867576078633\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(config['epochs']):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45361ada",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:46:20.183020Z",
     "iopub.status.busy": "2022-03-15T20:46:20.182069Z",
     "iopub.status.idle": "2022-03-15T20:46:20.184110Z",
     "shell.execute_reply": "2022-03-15T20:46:20.184520Z",
     "shell.execute_reply.started": "2022-03-15T19:41:02.555107Z"
    },
    "papermill": {
     "duration": 1.437939,
     "end_time": "2022-03-15T20:46:20.184660",
     "exception": false,
     "start_time": "2022-03-15T20:46:18.746721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "            \n",
    "            ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "            mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "            labels = batch['labels'].to(device, dtype = torch.long)\n",
    "            \n",
    "            loss, eval_logits = model(input_ids=ids, attention_mask=mask, labels=labels,\n",
    "                                     return_dict=False)\n",
    "            \n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += labels.size(0)\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += labels.size(0)\n",
    "        \n",
    "            if idx % 100==0:\n",
    "                loss_step = eval_loss/nb_eval_steps\n",
    "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
    "              \n",
    "            # compute evaluation accuracy\n",
    "            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
    "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "            \n",
    "            # only compute accuracy at active labels\n",
    "            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
    "        \n",
    "            labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "            \n",
    "            eval_labels.extend(labels)\n",
    "            eval_preds.extend(predictions)\n",
    "            \n",
    "            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    labels = [ids_to_labels[id.item()] for id in eval_labels]\n",
    "    predictions = [ids_to_labels[id.item()] for id in eval_preds]\n",
    "    \n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a20b918",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:46:23.285279Z",
     "iopub.status.busy": "2022-03-15T20:46:23.284344Z",
     "iopub.status.idle": "2022-03-15T20:47:51.225705Z",
     "shell.execute_reply": "2022-03-15T20:47:51.226192Z",
     "shell.execute_reply.started": "2022-03-15T19:41:02.569764Z"
    },
    "papermill": {
     "duration": 89.603252,
     "end_time": "2022-03-15T20:47:51.226343",
     "exception": false,
     "start_time": "2022-03-15T20:46:21.623091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validation loss per 100 evaluation steps: 0.431619793176651\n",
      "Validation loss per 100 evaluation steps: 0.3352778036110472\n",
      "Validation Loss: 0.32694979906082156\n",
      "Validation Accuracy: 0.39019523266173395\n"
     ]
    }
   ],
   "source": [
    "labels, predictions = valid(model, testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "727ce4ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:47:54.045510Z",
     "iopub.status.busy": "2022-03-15T20:47:54.040163Z",
     "iopub.status.idle": "2022-03-15T20:47:54.051046Z",
     "shell.execute_reply": "2022-03-15T20:47:54.051488Z",
     "shell.execute_reply.started": "2022-03-15T19:42:26.129595Z"
    },
    "papermill": {
     "duration": 1.423048,
     "end_time": "2022-03-15T20:47:54.051649",
     "exception": false,
     "start_time": "2022-03-15T20:47:52.628601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentence = \"@HuggingFace is a company based in New York, but is also has employees working in Paris\"\n",
    "model.eval()\n",
    "def inference(sentence):\n",
    "    inputs = tokenizer(sentence,\n",
    "#                         is_split_into_words=True, \n",
    "                        return_offsets_mapping=True, \n",
    "                        padding='max_length', \n",
    "                        truncation=True, \n",
    "                        max_length=config['max_length'],\n",
    "                        return_tensors=\"pt\")\n",
    "\n",
    "    # move to gpu\n",
    "    ids = inputs[\"input_ids\"].to(device)\n",
    "    mask = inputs[\"attention_mask\"].to(device)\n",
    "    # forward pass\n",
    "    outputs = model(ids, attention_mask=mask, return_dict=False)\n",
    "    logits = outputs[0]\n",
    "    \n",
    "    active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "    flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
    "    token_predictions = [ids_to_labels[i] for i in flattened_predictions.cpu().numpy()]\n",
    "    wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
    "\n",
    "    prediction = []\n",
    "    out_str = []\n",
    "    off_list = inputs[\"offset_mapping\"].squeeze().tolist()\n",
    "    for idx, mapping in enumerate(off_list):\n",
    "#         print(mapping, token_pred[1], token_pred[0],\"####\")\n",
    "\n",
    "#         only predictions on first word pieces are important\n",
    "        if mapping[0] != 0 and mapping[0] != off_list[idx-1][1]:\n",
    "#             print(mapping, token_pred[1], token_pred[0])\n",
    "            prediction.append(wp_preds[idx][1])\n",
    "            out_str.append(wp_preds[idx][0])\n",
    "        else:\n",
    "            if idx == 1:\n",
    "                prediction.append(wp_preds[idx][1])\n",
    "                out_str.append(wp_preds[idx][0])\n",
    "            continue\n",
    "    return prediction, out_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34d74237",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:47:56.880988Z",
     "iopub.status.busy": "2022-03-15T20:47:56.880316Z",
     "iopub.status.idle": "2022-03-15T20:47:56.924401Z",
     "shell.execute_reply": "2022-03-15T20:47:56.924857Z",
     "shell.execute_reply.started": "2022-03-15T19:59:41.425443Z"
    },
    "papermill": {
     "duration": 1.487086,
     "end_time": "2022-03-15T20:47:56.925033",
     "exception": false,
     "start_time": "2022-03-15T20:47:55.437947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 226.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>During a group project, have you ever asked a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18409261F5C2</td>\n",
       "      <td>80% of Americans believe seeking multiple opin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DF920E0A7337</td>\n",
       "      <td>Have you ever asked more than one person for h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D46BCB48440A</td>\n",
       "      <td>When people ask for advice,they sometimes talk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text\n",
       "0  0FB0700DAF44  During a group project, have you ever asked a ...\n",
       "1  D72CB1C11673  Making choices in life can be very difficult. ...\n",
       "2  18409261F5C2  80% of Americans believe seeking multiple opin...\n",
       "3  DF920E0A7337  Have you ever asked more than one person for h...\n",
       "4  D46BCB48440A  When people ask for advice,they sometimes talk..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_names, test_texts = [], []\n",
    "for f in tqdm(list(os.listdir('../input/feedback-prize-2021/test'))):\n",
    "    test_names.append(f.replace('.txt', ''))\n",
    "    test_texts.append(open('../input/feedback-prize-2021/test/' + f, 'r').read())\n",
    "test_texts = pd.DataFrame({'id': test_names, 'text': test_texts})\n",
    "# test_texts['text'] = test_texts['text'].apply(lambda x:x.split())\n",
    "test_texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82c99a10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:47:59.787730Z",
     "iopub.status.busy": "2022-03-15T20:47:59.786921Z",
     "iopub.status.idle": "2022-03-15T20:47:59.928780Z",
     "shell.execute_reply": "2022-03-15T20:47:59.927992Z",
     "shell.execute_reply.started": "2022-03-15T19:59:44.571250Z"
    },
    "papermill": {
     "duration": 1.539149,
     "end_time": "2022-03-15T20:47:59.928908",
     "exception": false,
     "start_time": "2022-03-15T20:47:58.389759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_texts = train_text_df['text'].tolist()[:10]\n",
    "y_pred = []\n",
    "\n",
    "for i, t in enumerate(test_texts['text'].tolist()):\n",
    "    o,o_t = inference(t)\n",
    "    y_pred.append(o)\n",
    "    l = train_text_df['entities'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65fb1370",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:48:03.019639Z",
     "iopub.status.busy": "2022-03-15T20:48:03.018647Z",
     "iopub.status.idle": "2022-03-15T20:48:03.029468Z",
     "shell.execute_reply": "2022-03-15T20:48:03.028760Z",
     "shell.execute_reply.started": "2022-03-15T19:59:48.279247Z"
    },
    "papermill": {
     "duration": 1.475622,
     "end_time": "2022-03-15T20:48:03.029631",
     "exception": false,
     "start_time": "2022-03-15T20:48:01.554009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 1730.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0FB0700DAF44', 'Claim', '49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "final_preds = []\n",
    "import pdb\n",
    "for i in tqdm(range(len(test_texts))):\n",
    "#     pdb.set_trace()\n",
    "    idx = test_texts.id.values[i]\n",
    "#     pred = ['']*len(test_texts[i])\n",
    "\n",
    "#     for j in range(len(y_pred[i])):\n",
    "#         if words[i][j] != None:\n",
    "#             pred[words[i][j]] = labels[y_pred[i][j]]\n",
    "\n",
    "    pred = [x.replace('B-','').replace('I-','') for x in y_pred[i]]\n",
    "#     print(pred)\n",
    "    preds = []\n",
    "    j = 0\n",
    "    while j < len(pred):\n",
    "        cls = pred[j]\n",
    "#         pdb.set_trace()\n",
    "        if cls == 'O':\n",
    "            j += 1\n",
    "        end = j + 1\n",
    "        while end < len(pred) and pred[end] == cls:\n",
    "            end += 1\n",
    "            \n",
    "        if cls != 'O' and cls != '' and end - j > 10:\n",
    "            final_preds.append((idx, cls, ' '.join(map(str, list(range(j, end))))))\n",
    "        \n",
    "        j = end\n",
    "        \n",
    "print(final_preds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2cbbe13b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:48:05.846280Z",
     "iopub.status.busy": "2022-03-15T20:48:05.845690Z",
     "iopub.status.idle": "2022-03-15T20:48:05.860038Z",
     "shell.execute_reply": "2022-03-15T20:48:05.859448Z",
     "shell.execute_reply.started": "2022-03-15T19:59:51.265860Z"
    },
    "papermill": {
     "duration": 1.408849,
     "end_time": "2022-03-15T20:48:05.860187",
     "exception": false,
     "start_time": "2022-03-15T20:48:04.451338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18409261F5C2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D46BCB48440A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DF920E0A7337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  class  predictionstring\n",
       "0  18409261F5C2    NaN               NaN\n",
       "1  D46BCB48440A    NaN               NaN\n",
       "2  0FB0700DAF44    NaN               NaN\n",
       "3  D72CB1C11673    NaN               NaN\n",
       "4  DF920E0A7337    NaN               NaN"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(final_preds))\n",
    "test_df = pd.read_csv('../input/feedback-prize-2021/sample_submission.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0112f8e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:48:09.164340Z",
     "iopub.status.busy": "2022-03-15T20:48:09.163518Z",
     "iopub.status.idle": "2022-03-15T20:48:09.165996Z",
     "shell.execute_reply": "2022-03-15T20:48:09.165554Z",
     "shell.execute_reply.started": "2022-03-15T20:00:03.915243Z"
    },
    "papermill": {
     "duration": 1.887942,
     "end_time": "2022-03-15T20:48:09.166113",
     "exception": false,
     "start_time": "2022-03-15T20:48:07.278171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(final_preds)\n",
    "sub.columns = test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb86c618",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:48:12.034926Z",
     "iopub.status.busy": "2022-03-15T20:48:12.029108Z",
     "iopub.status.idle": "2022-03-15T20:48:12.039820Z",
     "shell.execute_reply": "2022-03-15T20:48:12.039404Z",
     "shell.execute_reply.started": "2022-03-15T20:00:06.471895Z"
    },
    "papermill": {
     "duration": 1.420554,
     "end_time": "2022-03-15T20:48:12.039951",
     "exception": false,
     "start_time": "2022-03-15T20:48:10.619397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Claim</td>\n",
       "      <td>49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Position</td>\n",
       "      <td>108 109 110 111 112 113 114 115 116 117 118 119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Claim</td>\n",
       "      <td>122 123 124 125 126 127 128 129 130 131 132 13...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id     class                                   predictionstring\n",
       "0  0FB0700DAF44      Lead  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...\n",
       "1  0FB0700DAF44     Claim  49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 6...\n",
       "2  0FB0700DAF44  Evidence  85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 1...\n",
       "3  0FB0700DAF44  Position    108 109 110 111 112 113 114 115 116 117 118 119\n",
       "4  0FB0700DAF44     Claim  122 123 124 125 126 127 128 129 130 131 132 13..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3bfc9d87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T20:48:15.124230Z",
     "iopub.status.busy": "2022-03-15T20:48:15.123318Z",
     "iopub.status.idle": "2022-03-15T20:48:15.130420Z",
     "shell.execute_reply": "2022-03-15T20:48:15.129953Z",
     "shell.execute_reply.started": "2022-03-15T20:00:09.161365Z"
    },
    "papermill": {
     "duration": 1.430203,
     "end_time": "2022-03-15T20:48:15.130535",
     "exception": false,
     "start_time": "2022-03-15T20:48:13.700332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030e0f1b",
   "metadata": {
    "papermill": {
     "duration": 1.415063,
     "end_time": "2022-03-15T20:48:17.950419",
     "exception": false,
     "start_time": "2022-03-15T20:48:16.535356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da45b848",
   "metadata": {
    "papermill": {
     "duration": 1.454632,
     "end_time": "2022-03-15T20:48:20.913907",
     "exception": false,
     "start_time": "2022-03-15T20:48:19.459275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef4b73e",
   "metadata": {
    "papermill": {
     "duration": 1.660695,
     "end_time": "2022-03-15T20:48:24.060859",
     "exception": false,
     "start_time": "2022-03-15T20:48:22.400164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2886.601702,
   "end_time": "2022-03-15T20:48:28.956062",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-15T20:00:22.354360",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
